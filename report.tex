\documentclass[11pt,a4paper]{article}

\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{cite}
\geometry{margin=1in}

\title{Report on \\ \textbf{Online Learning for Min Sum Set Cover and Pandora's Box}}
\author{
    Kasionis Ioannis \\ University of Piraeus \\ \texttt{ioannis.kasionis@gmail.com}
    \and
    Triantafyllos Petros \\ University of Piraeus \\ \texttt{petrostriantafyllos@outlook.com}
}
\date{January 2025}

\begin{document}

\maketitle

\begin{abstract}
This report presents an analysis and summary of the paper \textit{Online Learning for Min Sum Set Cover and Pandora's Box} which provides a simple but effective skeleton for crafting online leaning algorithms for the \textit{Pandora's Box Problem}, the \textit{Min Sum Set Cover Problem (MSSC)}, and other related problems in the field of \textit{Stochastic optimization} \cite{gergatsouli2022online}. Traditionally, these problems assume prior knowledge of value distributions. However, in this work, we explore an online learning approach where we are presented with information over multiple rounds. \par 
Furthermore, the research, extends this framework to a bandit setting where only the values of the opened boxes are shown to the learner after each round.This extention also encompasses other alternatives of the above-mentioned problems \cite{gergatsouli2022online}.
\end{abstract}
\pagebreak

\section{Introduction}
The two essential problems in \textit{Stochastic Optimization} are the \textit{Pandora's Box}, and \textit{MSSC} problems.
Introduced, by Weitzman \cite{weitzman1978optimal} the \textit{Pandora's Box} problem offers a general framework for optimizing decisions under uncertainty, thus the goal is to minimize the cost of uncovering information.
\textit{MSSC}, a variation of \textit{Pandora's box}, deals with scenarios where values are either $0$ or $\infty$ \cite{feige2004approximating}. \par
While the traditional formulation of these problems assumes access to known stochastic distributions \cite{gergatsouli2022online}, this study extends these frameworks to \textit{online} settings, where data arrives sequentially without prior distributional knowledge. \par
The \textit{online learning} perspective brings forth several challenges and opportunities. In this model, adversarial instances or independent scenarios are presented iteratively, and the algorithm must decide on the next action based on the current state and previous observations. The performance metric typically revolves around \textit{regret}, measuring the algorithm's cumulative cost relative to an optimal offline policy \cite{shalev2012online}.
\newline

The work's primary contributions are as follows:
\begin{enumerate}
    \item Propose a computationally efficient online algorithm that achieves constant-competitive guarantees for both MSSC and Pandora's Box generalizations in full-information settings. This includes problems with complex constraints such as matroid bases \cite{bansal2010constant}.
    \item Extend the analysis to \textit{bandit settings}, where only partial feedback about the explored options is available \cite{flaxman2004online}. Despite these limited observations, our algorithm maintains a logarithmic regret bound, providing robust performance guarantees.
    \item Leveraging convex relaxations and online convex optimization techniques, demonstrate practical approximation strategies that bridge theoretical insights with computational efficiency \cite{shalev2007primal}.
\end{enumerate}

The implications of these results are twofold. First, they broaden the applicability of MSSC and Pandora's Box to dynamic, real-world contexts where decisions must adapt to unfolding events. Second, the integration of online convex optimization frameworks highlights the role of mathematical tools in addressing combinatorial challenges \cite{gergatsouli2022online}.

The remainder of the paper is organized as follows. Section 2 presents the problem formulations and related work, Section 3 details the proposed methods, and Sections 4 and 5 provide theoretical analyses and experimental evaluations, respectively. It concludes with discussions on potential future extensions.
\pagebreak

\section{Problem Definitions}
\subsection{Pandora’s Box Problem}
The Pandora’s Box problem involves a set of \( n \) boxes, each containing an unknown value and an associated cost to open. The objective is to determine an order in which to open the boxes to minimize the combined cost of inspection and the value of the selected item. Specifically, given a distribution of potential values and costs for each box, the goal is to identify an optimal strategy that balances exploration (opening boxes) and exploitation (choosing the best available value). 

In the online variant considered in this work, values and costs for the boxes are revealed adversarially over \( T \) rounds, requiring the learner to adopt strategies that adapt to newly presented information while minimizing regret against an optimal offline policy.

\subsection{Min Sum Set Cover (MSSC)}
The MSSC problem is a special case of Pandora’s Box where the values (or costs) inside the boxes are restricted to either \( 0 \) or \( \infty \). The MSSC is particularly relevant in applications where binary outcomes dictate whether an item satisfies certain criteria.
\pagebreak


\section{Methodologies}
Summarize the key approaches used in the paper, including:
\begin{itemize}
    \item Convex relaxations for online learning.
    \item Online convex optimization frameworks.
    \item Rounding techniques for fractional to integral solutions.
\end{itemize}

\section{Results}
Detail the main results:
\begin{itemize}
    \item Competitive ratios achieved for Pandora's Box and MSSC.
    \item Extensions to bandit settings.
    \item Performance under matroid constraints.
\end{itemize}

\section{Comparison with Previous Work}
This work builds upon the foundational results in stochastic optimization, particularly in the domains of Pandora’s Box and MSSC. Previous studies have focused on the stochastic case, where values and costs are drawn from known distributions, enabling efficient offline algorithms and partially adaptive strategies \cite{weitzman1978optimal, chawla2020pandora}.

In contrast, our study addresses the online setting where adversarially chosen values and costs are presented over multiple rounds. Notably, our framework simplifies the implementation of competitive algorithms through convex relaxations and online convex optimization techniques, extending prior work by providing guarantees in bandit settings \cite{gergatsouli2022online}. Furthermore, our results generalize MSSC algorithms, achieving constant-factor approximations even under matroid constraints, a challenge that previous work struggled to address effectively \cite{feige2004approximating}.

\section{Applications and Future Work}
The results of this study have practical implications in various domains, including:
\begin{itemize}
    \item \textbf{Resource Allocation:} Optimizing inspection costs in applications such as manufacturing and quality assurance.
    \item \textbf{Search Algorithms:} Enhancing strategies for finding optimal solutions under uncertain information.
    \item \textbf{Online Auctions:} Adapting bidding strategies in adversarial settings.
\end{itemize}

Future work could explore extending the framework to dynamic settings where constraints evolve over time or incorporating richer feedback mechanisms in the bandit setting. Additionally, improving the approximation factors under more complex combinatorial constraints remains an open challenge with significant theoretical and practical relevance.
\pagebreak

\section{Conclusion}
This work presented a comprehensive framework for addressing the online versions of Pandora’s Box and Min Sum Set Cover (MSSC), two cornerstone problems in stochastic optimization. By leveraging convex relaxations and online convex optimization techniques, the authors developed efficient algorithms that achieve constant competitiveness under full information and bandit settings. These algorithms extend the capabilities of previous approaches, particularly in handling adversarially chosen inputs and accommodating complex constraints such as matroids \cite{gergatsouli2022online}.

\appendix
\section{Appendix}
Include any additional proofs, explanations, or extended results here.

\bibliographystyle{unsrt}
\bibliography{report}
\end{document}